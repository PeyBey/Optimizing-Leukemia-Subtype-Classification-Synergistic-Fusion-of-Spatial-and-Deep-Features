{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396},"id":"JKTabwlTFiay","executionInfo":{"status":"error","timestamp":1665519225393,"user_tz":-120,"elapsed":1999,"user":{"displayName":"Shima Rastgordani","userId":"05662421592648252049"}},"outputId":"941a27b0-f979-4614-e139-90b29329bc74"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-001d41ff0a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv2DTranspose\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUpSampling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Codes'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mephemeral\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m       readonly=readonly)\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must be in a directory that exists'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m   \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_signal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGKILL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Mountpoint must be in a directory that exists"]}],"source":["from os import listdir\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg19 import VGG19\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.vgg16 import preprocess_input\n","from keras.models import Model\n","import cv2\n","from glob import glob\n","import os\n","from sklearn.preprocessing import MinMaxScaler\n","from sys import path\n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.metrics import RootMeanSquaredError\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, AveragePooling2D, GlobalMaxPooling2D\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","import pandas as pd\n","from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Convolution2D , MaxPooling2D\n","from tensorflow.keras.optimizers import RMSprop, Adam, Adadelta\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.layers.convolutional import Conv2D\n","from tensorflow.keras.layers import BatchNormalization\n","from keras.layers.convolutional import MaxPooling2D\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import keras.backend as K\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.layers import Conv2DTranspose , Concatenate, UpSampling2D\n","from google.colab import drive\n","drive.mount('/content/drive/' , force_remount=True)\n","\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.applications import InceptionV3, Xception\n","\n","\n","def augumentaion(folder , dim):\n","  X = []\n","  img_file = cv2.imread( folder +'test_img.jpg')\n","  if img_file is not None:\n","      img_orginal=cv2.resize(img_file,dim)\n","      img_arr = np.asarray(img_orginal)\n","      X.append(img_arr)\n","      \n","  else:\n","    print('Not Image')\n","  X_new=np.asarray(X)\n","  return X_new\n","Input_path= \"/content/drive/MyDrive/Codes/\"\n","dim=(224,224)\n","X = augumentaion(Input_path, dim)\n","def VGG():\n","    inputShape=tuple(list(dim)+[3])\n","    inputs = Input(shape=inputShape)\n","    base_model = VGG16(weights=None, include_top=False, input_shape=inputShape)\n","    outputs = base_model.output\n","    outputs = Conv2D(400, kernel_size= (1,1))(outputs)\n","    outputs = Flatten(name='flatten')(outputs)\n","    outputs = Dense(160)(outputs)\n","    outputs= Activation(\"relu\")(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    prediction = Dense(3,activation=\"linear\")(outputs)\n","    model_vgg16 = Model(base_model.input, outputs=prediction , name=\"Vgg16\")\n","    return model_vgg16\n","opt = Adam(learning_rate=0.0001)\n","metric= RootMeanSquaredError()\n","lossfunc='mse'\n","VGG = VGG() \n","VGG.compile(optimizer=opt, loss=lossfunc, metrics=metric)\n","def Resnet():\n","    inputShape=tuple(list(dim)+[3])\n","    inputs = Input(shape=inputShape)\n","    base_model = ResNet50(weights=None, include_top=False, input_shape=inputShape)\n","    outputs = base_model.output\n","    outputs = Conv2D(240, kernel_size= (1,1))(outputs)\n","    outputs = Flatten(name='flatten')(outputs)\n","    outputs = Dense(992)(outputs)\n","    outputs= Activation(\"relu\")(outputs)\n","    outputs = Dense(992)(outputs)\n","    outputs= Activation(\"relu\")(outputs)\n","    outputs = Dense(32)(outputs)\n","    outputs= Activation(\"relu\")(outputs)\n","    outputs = BatchNormalization()(outputs)\n","    prediction = Dense(3,activation=\"linear\")(outputs)\n","    model_resnet50 = Model(base_model.input, outputs=prediction , name=\"Resnet50\")\n","\n","    return model_resnet50\n","lr = 0.01\n","opt = Adam(learning_rate=lr)\n","# compile the model\n","metric= RootMeanSquaredError()\n","lossfunc='mse'\n","Resnet = Resnet() \n","Resnet.compile(optimizer=opt, loss=lossfunc, metrics=metric)\n","os.chdir('/content/drive/MyDrive/Codes')\n","import h5py\n","from tensorflow.keras.models import load_model\n","model1 = Resnet\n","model1.load_weights('Resnet_weights.h5')\n","model2 = VGG\n","model2.load_weights('Vgg16_weights.h5')\n","def extractFeatures(X,model):\n","    model.layers.pop()\n","    model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","    #print(model.summary())\n","\n","    # feature extraction from photos\n","    features = []\n","    i=0\n","\n","\n","    for x in X:\n","        x = x.reshape((1, x.shape[0], x.shape[1], x.shape[2]))\n","        x = preprocess_input(x)\n","        features.append(model.predict(x, verbose = 0))\n","        i+=1\n","    features=np.array(features)\n","    \n","    return features\n","feats1 = extractFeatures(X,model1)\n","feats2 = extractFeatures(X,model2)\n","feats1=np.array(feats1)\n","XNew1=feats1.reshape(feats1.shape[0],feats1.shape[2])\n","feats2=np.array(feats2)\n","XNew2=feats2.reshape(feats2.shape[0],feats2.shape[2])\n","XNew=np.concatenate((XNew1, XNew2), axis=1)\n","import joblib\n","os.chdir('/content/drive/MyDrive/Codes')\n","reg_model1 = joblib.load(\"./Adaboost.joblib\")\n","reg_model2 = joblib.load(\"./Randomforest.joblib\")\n","Out1 = reg_model1.predict(XNew)\n","Out2 = reg_model2.predict(XNew)\n","print('Normalized Adaboost Output')\n","print(Out1)\n","print('Normalized Randomforest Output')\n","print(Out2)\n"]}]}